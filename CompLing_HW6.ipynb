{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af66482",
   "metadata": {},
   "source": [
    "#### Важное требование ко всей домашке в целом: в jupyter ноутбуке не должно был лишнего кода (т.е. если вы взяли за основу семинар, не забудьте удалить все лишнее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aed5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 16:34:13.662677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:34:13.662742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff0edb5-a479-4ce5-83bd-4993e63767fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed908832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)\n",
    "svd = TruncatedSVD(200)\n",
    "\n",
    "X = cv.fit_transform(wiki)\n",
    "X_svd = svd.fit_transform(X)\n",
    "\n",
    "embeddings = svd.components_.T\n",
    "\n",
    "id2word = cv.get_feature_names_out()\n",
    "word2id = {word:i for i,word in enumerate(id2word)}\n",
    "\n",
    "def most_similar(word, embeddings):\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:10]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6a3d16-6b0e-45f8-9ea4-5ecbbd7c8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c40fa06-6e60-4882-b8fe-2ef14605ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c422aa0",
   "metadata": {},
   "source": [
    "# Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a72790",
   "metadata": {},
   "source": [
    "Обучите word2vec модели с негативным семплированием (cbow и skip-gram) с помощью tensorflow аналогично тому, как это было сделано в семинаре. Вам нужно изменить следующие пункты: \n",
    "1) добавьте лемматизацию в предобработку (любым способом)  \n",
    "2) измените размер окна на 6 для cbow и 12 для skip gram (обратите внимание, что размер окна = #слов слева + #слов справа, в gen_batches в семинаре window не так используется)  \n",
    "3) измените часть с np.random.randint(vocab_size) так, чтобы случайные негативные примеры выбирались обратно пропорционально частотностям слов (частотные должны выбираться реже, а редкие чаще)\n",
    "\n",
    "Выберете несколько не похожих по смыслу слов, и протестируйте полученные эмбединги (найдите ближайшие слова и оцените правильность, как в семинаре)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde5fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация тута здеся\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f71d7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in wiki:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613f3a73-e4f4-40e1-994b-68b99c2fe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = []\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e4d5d3-5cce-4771-9aef-8e1b17527734",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "    \n",
    "    \n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9266c6e9-6638-40a9-8a5f-9f928ad3a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for text in wiki:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    sentences.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63de742-40e4-4144-b54a-29a06869c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(id2word)\n",
    "\n",
    "# вероятности посчитаны так\n",
    "num_occur = sum(vocab[i] for i in filtered_vocab)\n",
    "probs = [vocab[i] / num_occur for i in filtered_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb36598-7fe6-4e6c-8881-1a97e3aa95f9",
   "metadata": {},
   "source": [
    "### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "681a3c3e-0127-468f-80d1-02faa5ddd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches_sg(sentences, window, use_ns, batch_size=1000): # здеся добавлен аргумент use_ns (типа если хочу negative sampling)\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    if use_ns == True: # а это отдельный if statement для негативного семплирования\n",
    "                        X_target.append(word)\n",
    "                        X_context.append(word2id[np.random.choice(filtered_vocab, p=probs)])\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        X_target.append(word)\n",
    "                        X_context.append(np.random.randint(vocab_size))\n",
    "                        y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21151ff-c750-4526-981c-82702cf437fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 16:41:00.852123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-27 16:41:00.852487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852687: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-27 16:41:00.852827: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-27 16:41:00.853216: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e154ad-bf17-4b4c-98de-6843eb5d5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1015s 1s/step - loss: 0.6849 - accuracy: 0.5488 - val_loss: 0.6948 - val_accuracy: 0.5107\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1056s 1s/step - loss: 0.6688 - accuracy: 0.5701 - val_loss: 0.6866 - val_accuracy: 0.5344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b10a20e20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_sg(sentences[:19000], window=12, use_ns=True),\n",
    "          validation_data=gen_batches_sg(sentences[19000:],  window=12, use_ns=True),\n",
    "          batch_size=10000,\n",
    "          steps_per_epoch=1000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882f4c9c-f5ec-42bb-a63a-c8ccff5b37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_sg = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2d448-8c63-48b2-908d-687f226ae314",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a021ae78-90e9-456f-b38e-af3506f41e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_batches_cbow(sentences, window, use_ns, batch_size=1000): # здеся добавлен аргумент use_ns (типа если хочу negative sampling)\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "                \n",
    "                if use_ns == True: # а это отдельный if statement для негативного семплирования\n",
    "                    X_target.append(word2id[np.random.choice(filtered_vocab, p=probs)])\n",
    "                    X_context.append(context)\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = tf.keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window*2)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93201a85-31b1-495d-abfb-30e97e27eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(10,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(embeddings_context)\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "\n",
    "# полученную близость нужно преобразовать в вероятность\n",
    "# когда она одна используется не софтмакс и сигмоида\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b243e6e-bcc0-4943-b73f-6822dd2ef66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 5412s 1s/step - loss: 0.5013 - accuracy: 0.7473 - val_loss: 0.4211 - val_accuracy: 0.8057\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 5924s 1s/step - loss: 0.3951 - accuracy: 0.8209 - val_loss: 0.3965 - val_accuracy: 0.8187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3acd7ce7c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_cbow(sentences[:19000], window=6, use_ns=True),\n",
    "          validation_data=gen_batches_cbow(sentences[19000:],  window=6, use_ns=True),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d8dcb9-deaa-46e7-a07e-79aff45c6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cbow = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e5134-0d48-4296-84f8-1dacaf133b61",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49eb42fa-d64f-4404-8b94-03547bcbddb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['больница',\n",
       " 'бронзовым',\n",
       " 'берегах',\n",
       " 'андреа',\n",
       " 'лицом',\n",
       " 'выполнении',\n",
       " 'близких',\n",
       " 'архитектора',\n",
       " 'дивизию',\n",
       " 'войн']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('больница', embeddings_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aee22406-2d71-487b-b45e-6ea984c6884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['больница',\n",
       " 'ата',\n",
       " 'предотвратить',\n",
       " 'больнице',\n",
       " '1907',\n",
       " '1914',\n",
       " 'был',\n",
       " 'предположение',\n",
       " 'практика',\n",
       " 'бронзовым']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('больница', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "144c0416-4c0f-48f3-8c30-21d9637bef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['небо',\n",
       " 'госпиталь',\n",
       " 'иоанном',\n",
       " 'игре',\n",
       " 'знаком',\n",
       " 'игрового',\n",
       " '36',\n",
       " '99',\n",
       " 'души',\n",
       " 'говорит']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('небо', embeddings_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "638921e9-c717-4237-a14c-016846476756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['небо',\n",
       " 'направлению',\n",
       " 'восточном',\n",
       " 'раз',\n",
       " 'требуется',\n",
       " 'имеющих',\n",
       " 'продюсером',\n",
       " 'говорит',\n",
       " 'общественного',\n",
       " 'составлял']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('небо', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cfba4be-0faf-4de8-99b8-6cbb319b4052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['общество',\n",
       " 'обществом',\n",
       " 'орган',\n",
       " 'переезжает',\n",
       " 'dvd',\n",
       " 'альбоме',\n",
       " 'пожара',\n",
       " '1000',\n",
       " '1921',\n",
       " 'обращается']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('общество', embeddings_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59697513-8568-4828-a883-10d2f470e2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['общество',\n",
       " 'племени',\n",
       " 'принимают',\n",
       " 'полюса',\n",
       " 'рода',\n",
       " 'ленинграде',\n",
       " 'равно',\n",
       " 'сил',\n",
       " 'племён',\n",
       " 'швейцарии']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('общество', embeddings_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b12a9-e404-456f-b0a7-3ab745c778a6",
   "metadata": {},
   "source": [
    "Оказалось, что вообще все мимо. Только потом заметила, что окно пополам не поделила. Запомню на будущее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b61b7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff080",
   "metadata": {},
   "source": [
    "Обучите 1 word2vec и 1 fastext модель в gensim. В каждой из модели нужно задать все параметры, которые мы разбирали на семинаре. Заданные значения должны отличаться от дефолтных и от тех, что мы использовали на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "986c2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5035bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocess(text) for text in wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee20262-e3c9-41cd-847e-bc5f8408e148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 193 ms, total: 1min 8s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                            vector_size=100,\n",
    "                            min_count=10,\n",
    "                            max_vocab_size=None,\n",
    "                            window=7,\n",
    "                            epochs=10,\n",
    "                            hs=1,\n",
    "                            negative=0,\n",
    "                            sample=0.0001,\n",
    "                            cbow_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeb78161-03c7-42b6-87aa-ba0dbd8aa97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 2s, sys: 366 ms, total: 6min 2s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts,\n",
    "                            vector_size=100,\n",
    "                            min_count=10,\n",
    "                            max_vocab_size=None,\n",
    "                            window=7,\n",
    "                            epochs=10,\n",
    "                            hs=1,\n",
    "                            negative=0,\n",
    "                            sample=0.0001,\n",
    "                            min_n=4,\n",
    "                            max_n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb928c",
   "metadata": {},
   "source": [
    "# Задание 3 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019b0d1",
   "metadata": {},
   "source": [
    "Используя датасет для классификации (labeled.csv) и простую нейронную сеть (последняя модель в семинаре), оцените качество полученных эмбедингов в задании 1 и 2 (4 набора эмбедингов), также проверьте 1 любую из предобученных моделей с rus-vectores (но только не tayga_upos_skipgram_300_2_2019). \n",
    "Какая модель показывает наилучший результат?\n",
    "\n",
    "Убедитесь, что для каждой модели вы корректно воспроизводите пайплайн предобработки (в 1 задании у вас лемматизация, не забудьте ее применить к датасету для классификации; у выбранной предобученной модели может быть своя специфичная предобработка - ее нужно воспроизвести)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c05b56-9d75-45f0-b714-b191032de119",
   "metadata": {},
   "source": [
    "Выбранная модель -- ruwikiruscorpora_upos_cbow_300_10_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60c18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78429d22-1fe7-47ff-94f1-a9386fc22911",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data['norm_text'] = data.comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e40f97a-605d-4a9f-9a74-f7d15a86b2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6220"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in data['norm_text']:\n",
    "    vocab.update(text)\n",
    "    \n",
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 5:\n",
    "        filtered_vocab.add(word)\n",
    "\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47d908a2-e866-4588-ae26-a21eeebb286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2c5ba75-1c5d-4153-92da-fe5d0c63f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for tokens in data['norm_text']:\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0547ca6-395c-4569-9f40-6aba0c78828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=100)\n",
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c1006a0-d208-4409-933f-9ceea608394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f871c82f-0686-48da-885d-49d2f11ea8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs, )\n",
    "# embedding слой возвращает последовательность векторов\n",
    "# а нам нужно классифицировать сразу весь текст\n",
    "# стандартный подход в этом случае - усреднить единичные вектора в 1 вектор текста\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "# к усредненному вектору мы уже применяем полносвязный слой, который вернет вероятность токсичности\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d271172e-9a08-4433-8483-1c02a7f1188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "428/428 [==============================] - 3s 7ms/step - loss: 0.6268 - accuracy: 0.6643 - val_loss: 0.5982 - val_accuracy: 0.6630\n",
      "Epoch 2/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.5401 - accuracy: 0.6938 - val_loss: 0.5180 - val_accuracy: 0.7143\n",
      "Epoch 3/10\n",
      "428/428 [==============================] - 3s 6ms/step - loss: 0.4436 - accuracy: 0.8135 - val_loss: 0.4567 - val_accuracy: 0.8141\n",
      "Epoch 4/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.3737 - accuracy: 0.8682 - val_loss: 0.4206 - val_accuracy: 0.8585\n",
      "Epoch 5/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.3254 - accuracy: 0.8873 - val_loss: 0.4124 - val_accuracy: 0.8419\n",
      "Epoch 6/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.2902 - accuracy: 0.9006 - val_loss: 0.4013 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.2631 - accuracy: 0.9095 - val_loss: 0.3927 - val_accuracy: 0.8641\n",
      "Epoch 8/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.2424 - accuracy: 0.9156 - val_loss: 0.3968 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "428/428 [==============================] - 2s 6ms/step - loss: 0.2237 - accuracy: 0.9232 - val_loss: 0.4022 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "428/428 [==============================] - 2s 5ms/step - loss: 0.2080 - accuracy: 0.9275 - val_loss: 0.4090 - val_accuracy: 0.8599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39179db280>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "529130e4-a2da-41e4-825b-80a3840b1878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
