{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67445cfb-5695-4b7f-b6c7-c148aacd0004",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8872c783-df2e-4992-ae6d-a0cbb0725017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7e5dd4-086f-436f-8f9e-141132c76ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach = open('2ch_corpus.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41160723-bac7-4f87-8d64-aaafeada9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция нормализации\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff748196-48bb-40d9-8cac-ee920f168439",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dvach = normalize(dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce50a42b-3ed6-4c01-b219-a18321564b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Превращение абсолютных частот в вероятности\n",
    "\n",
    "vocab_dvach = Counter(norm_dvach)\n",
    "probas_dvach = Counter({word:c/len(norm_dvach) for word, c in vocab_dvach.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514f2467-64df-477f-8e41-9e3d490b85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrammer(tokens, n=3):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fc475e-986e-453e-9510-c921f8c3a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "sentences_dvach_test = sentences_dvach[:5000]\n",
    "sentences_dvach = sentences_dvach[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8637d169-a2fc-4da6-9d56-236198f17f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "unigrams_dvach = Counter()\n",
    "\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    trigrams_dvach.update(ngrammer(sentence,3))\n",
    "    bigrams_dvach.update(ngrammer(sentence,2))\n",
    "    unigrams_dvach.update(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdd2a43-1411-4f39-9ce0-2f519ed7f099",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "trigrams_dvach = Counter()\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    trigrams_dvach.update(ngrammer(sentence))\n",
    "    bigrams_dvach.update(ngrammer(sentence,2))\n",
    "    unigrams_dvach.update(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acec0cd5-c475-47a0-90c4-6be272ae6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fe8c41-dbc0-424b-9e47-77f6ab156d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = lil_matrix((len(bigrams_dvach), len(unigrams_dvach))) \n",
    "            \n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "\n",
    "id2bigram_dvach = list(bigrams_dvach)\n",
    "bigram2id_dvach = {word:i for i, word in enumerate(id2bigram_dvach)}\n",
    "\n",
    "for ngram in trigrams_dvach:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + ' ' + word2\n",
    "\n",
    "    matrix_dvach[bigram2id_dvach[bigram],word2id_dvach[word3]] =  (trigrams_dvach[ngram]/bigrams_dvach[bigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76510711-a105-4656-977e-d06e534c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = csr_matrix(matrix_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac0d5ea-156d-4f63-b8b8-b454f27bd152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11030"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(list(range(matrix_dvach.shape[1])), \n",
    "                 p=matrix_dvach[1].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c5353d2-178b-40a3-a4ed-66e84c291c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2bigram, id2word, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    for i in range(n):\n",
    "        p = matrix[current_idx].toarray()[0]\n",
    "        chosen = np.random.choice(list(range(matrix.shape[1])), p = p)\n",
    "        text.append(id2word[chosen])\n",
    "        if id2word[chosen] == '<end>':\n",
    "            current_idx = bigram2id[start]\n",
    "        else:\n",
    "            part = id2bigram[current_idx] + ' ' + id2word[chosen]\n",
    "            part = ' '.join(part.split()[1:])\n",
    "            current_idx = bigram2id[part]\n",
    "    \n",
    "    return ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c86b14-48e5-44cc-ae2e-c87228d862f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пострадавшей диагностированы сотрясение головного мозга не уверен поэтому спрашиваю \n",
      " незнакомой ух блядь после такого вина подружились даже больше сделал уже были готовы к такому говноедству \n",
      " топология произведения \n",
      " а эти фото \n",
      " ну ты чего конкретно хочешь \n",
      " простой и быстрый \n",
      " я так дико хочется предложить фаллоут 4 но есть бесплатные курсы говно ипама при успешном попадании можно выбить пилота и или инструктора или без кодинга \n",
      " не проходишь на харде \n",
      " да просто отдыхать \n",
      " естественно пока она для бидла и саморазвивается анимой и комплухтерными играми живет на мельдониях \n",
      " вопросов более не живу и счастье\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2bigram_dvach, id2word_dvach, bigram2id_dvach, start='<start> <start>').replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce0300b8-b765-46f8-bccb-a2b1ffe57707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "адмиралы а токитсуказе оставляют лишь ради айдла \n",
      " колду лучше спирать \n",
      " то есть умрёшь но я лучше воспользуюсь аналогией \n",
      " крипово \n",
      " а батонинг в теме на 4 \n",
      " третья последняя из известных хоккеистов на фото будто посрала пиздой ты ещё захочешь \n",
      " именно из-за таких упырей как ты \n",
      " лазерный луч летит со скоростью с в госконторе 2 года подарков судьбы не планируется может позже \n",
      " ближайшие пол года-год \n",
      " это никакой пользы не приносит хороший результат \n",
      " с ума думаю уже с руководством типа \n",
      " обоссал быдлана \n",
      " мне важно что ты чувствовал когда сосал куну \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2bigram_dvach, id2word_dvach, bigram2id_dvach, start='<start> <start>').replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a48d96f-0fca-45e3-bfa3-3284101d4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "да говно она как раз ту самую копеечку все заводские документы \n",
      " потом переходите о тайнах подземной мск закажите с сайта вяжет кабеля не в школу и чувствуешь блядь как же я тебе запруфаю \n",
      " какой закат если время в растрепанной одежде это тоже самое плюс правда удобнее доставать из кармана сотку и ездить на любых животных 13 инициатива он не в убыток \n",
      " конечно карбидоборные и графитовые стержни деда похож на его месте предал бы почти всякий человек имеющий столько могущества ничего червепидорского как в малайзии пройти за геноцид ксеносов в ебенях космоса тоже есть свое мнение \n",
      " к\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2bigram_dvach, id2word_dvach, bigram2id_dvach, start='<start> <start>').replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54bd63eb-ee51-411a-9029-7cd51795f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probas):\n",
    "    p = np.exp(np.sum(probas))\n",
    "    N = len(probas)\n",
    "    \n",
    "    return p**(-1/N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22427f4f-75c3-4291-8334-911563debb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-29b2627a57da>:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return p**(-1/N)\n"
     ]
    }
   ],
   "source": [
    "all_perplexity = []\n",
    "for sent in sentences_dvach_test:\n",
    "    probs = []\n",
    "    for ngram in ngrammer(sent, 3):\n",
    "        word1, word2, word3 = ngram.split()\n",
    "        bigram = word1 + ' '+word2\n",
    "        \n",
    "        if ngram in trigrams_dvach and bigram in bigrams_dvach:\n",
    "            probs.append(np.log(trigrams_dvach[ngram]/bigrams_dvach[bigram]))\n",
    "        else:\n",
    "            probs.append(np.log(0.00001))\n",
    "    if perplexity(probs)!= np.inf: \n",
    "        all_perplexity.append(perplexity(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e1c11d-ac3f-4951-be8d-bfdb98fdf14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31601.41487175953"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0f5dd-9d88-4556-b141-35ff1c1c465c",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31cd59-60c5-459b-8911-7c30e3b8b9ca",
   "metadata": {},
   "source": [
    "1. Для несловарных слов можно добавить псевдо-слово <UNK> в тестовую выборку. Есть два способа вычислить вероятности для модели с несловарными словами:\n",
    "\n",
    "    1. Все несловарные слова в обучающей выборке сковертировать в токен <UNK> на этапе нормализации текста.\n",
    "    2. Заменить все словарные слова на токен <UNK> на основе их частотности (когда нет предопределенного словаря)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64eff0-50d6-49ad-a730-7c1b89020675",
   "metadata": {},
   "source": [
    "2. Сглаживание — это метод равномерного распределения вероятностей для исключения нулевых вероятностей в необычных контекстах. Есть несколько типов алгоритмов, самый простой из которых, — это сглаживание Лапласа. Оно заключается в том, что прибавляется 1 к каждому числу n-gram'ов. \n",
    "Еще можно рассматривать сглаживание как снижение ненулевых вероятностей, чтобы добавить эти вероятности к нулевым. Этот алгоритм можно описать через частное сниженного числа n-gram'ов и изначального."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74a62bdd49c95697c63e129ae50a6243abb25a054b23fd5800def67e099b9bbe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
